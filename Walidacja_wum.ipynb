{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8eb7f2a",
   "metadata": {},
   "source": [
    "# Wstęp do uczenia maszynowego. Projekt nr 1.\n",
    "\n",
    "*Maciej Borkowski, Michał Chęć\n",
    "21.04.2023r.*\n",
    "\n",
    "Walidowali: Alicja Charuza, Mateusz Gałęziewski\n",
    "\n",
    "Zadaniem projektowym jest zrealizowanie zadania klasyfikacji binarnej na zbiorze danych numerycznych ze strony\n",
    "[https://www.kaggle.com/datasets/nextbigwhat/dataset-1](https://www.kaggle.com/datasets/nextbigwhat/dataset-1)\n",
    "\n",
    "\n",
    "# UWAGA po pierwsze: brak pliku 'requirements', który jest niezbędny do pełnej reprodukcji wyników projektu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbae4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ładujemy potrzebne pakiety\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, SequentialFeatureSelector, RFE, VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0836c0c",
   "metadata": {},
   "source": [
    "# 1. Import i podział danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e59d7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wczytujemy całą ramkę danych\n",
    "dataset = pd.read_csv(\"dataset_1.csv\")\n",
    "df = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c11a7336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dzielimy dane, tworzymy zbiór do ewaluacji i do testów\n",
    "train_set, eval_set = train_test_split(df, test_size=0.3, random_state=42)\n",
    "train_df, test_df = train_test_split(train_set, test_size=0.3, random_state=42)\n",
    "df = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b2889e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03982, 0.04006666666666667, 0.039714285714285716]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#czy zmienna objaśniana ma mniej więcej ten sam współczynnik 1 w obu zbiorach\n",
    "[dataset[dataset.target == 1].size/dataset.size,\n",
    " eval_set[eval_set.target == 1].size/eval_set.size,\n",
    " train_set[train_set.target == 1].size/train_set.size]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79024479",
   "metadata": {},
   "source": [
    "# 2. EDA i preprocessing\n",
    "\n",
    "Na początek parę słów odnośnie eksploracyjnej analizy danych i preprocessingu. \n",
    "Zespół budowy poprawnie wykonuje wstępną analizę. Sprawdza występowanie braków danych, typów danych i ich rozmiar, czy zbiory: treningowy, testowy, walidacyjny są zbalansowane.\n",
    "Dobrym pomysłem zespołu budowy również jest oddzielna analiza eksploracyjna kolumn zawierających wartości w postaci liczb całkowitych jak i tych zawierających liczby zmiennoprzecinkowe. \n",
    "Pozbywając się kolumn zależnych, stałych, prawiestałych i zduplikowach zmniejszyli wymiarowość danych, co również uznajemy za słuszne.\n",
    "\n",
    "Dziwnym rozwiązaniem natomiast jest stosowanie oddzielnych preprocessingów dla każdego modelu z osobna. Biorąc jednakże pod uwagę syntetyczność danych oraz świadomość zespołu budowy jesteśmy w stanie zrozumieć takie podejście.  Na plus jest także tworzenie przez zespół budowy dydykowanych narzęci do eksploracyjnej analizy danych.\n",
    "\n",
    "Zespół budowy stworzył również od podstaw klasę 'ColumnRemover' do redukcji ilości kolumn, funkcja jest skomplikowana co ciekawe przyjmuje nawet parametry \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef98a4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24500, 301)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "222858ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_by_Var_threshold(df, threshold):\n",
    "    X = df.drop('target', axis=1)\n",
    "    \n",
    "    selector = VarianceThreshold(threshold=threshold)\n",
    "    selector.fit(X)\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "    X_selected = X[selected_features]\n",
    "    return X_selected.join(df.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30a95c16",
   "metadata": {},
   "source": [
    "### Poniżej widzimy ciekawy pomysł budujących\n",
    "Jak się później niestety okaże to przez jedną z poniższch funkcji nie będzie można przeprowadzić votingu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e42acaf",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class ColumnRemover(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, threshold_constant, threshold_corr, n_info_vals):\n",
    "        self.threshold_constant = threshold_constant\n",
    "        self.threshold_corr = threshold_corr\n",
    "        self.n_info_vals = n_info_vals\n",
    "        self.columns_to_remove = []\n",
    "        self.columns_to_keep = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # usuwanie zduplikowanych kolumn\n",
    "        self.columns_to_remove.extend(X.loc[:, X.T.duplicated()].columns.tolist())\n",
    "\n",
    "        # usuwanie stałych i prawie stałych kolumn\n",
    "        for column in X.columns:\n",
    "            if X[column].value_counts(normalize=True).iloc[0] >= self.threshold_constant:\n",
    "                self.columns_to_remove.append(column)\n",
    "\n",
    "        # usuwanie skorelowanych kolumn, jeśli pierwsza kolumna jest ciągła stosujemy korelację pearsona,\n",
    "        # jeśli dyskretna to korelację spearmana; pierwsza kolumna będzie typu takiego samego jak cały X ponieważ\n",
    "        # klasę tą stosujemy w column tranformerze ograniczając podzbiór kolumn do okreslonego typu\n",
    "        if X.dtypes[0] == 'float64':\n",
    "            corr = X.corr(method='pearson')\n",
    "        else:\n",
    "            corr = X.corr(method='spearman')\n",
    "        corr = corr[corr > self.threshold_corr]\n",
    "        dependent_columns = corr.apply(lambda row: row[row > 0].index, axis=1)\n",
    "        for j in range (len(dependent_columns)):\n",
    "            for k in dependent_columns[j]:\n",
    "                if k is not dependent_columns.index[j]:\n",
    "                    if k not in dependent_columns.index[0:j]:\n",
    "                        self.columns_to_remove.append(k)\n",
    "\n",
    "        # usuwanie kolumn nie niosących informacji\n",
    "        amount_of_ones = y[y == 1].shape[0]\n",
    "        X = X.join(y)\n",
    "        for column in X.columns:\n",
    "            tmp = X.groupby(column)['target'].agg(['sum','count']).sort_values('sum',ascending = False).reset_index()\n",
    "            if any(tmp[column] == 0) and (tmp.loc[tmp[column] == 0, 'sum'] > amount_of_ones - self.n_info_vals).bool():\n",
    "                self.columns_to_remove.append(column)\n",
    "        X.drop('target', axis=1, inplace=True)\n",
    "\n",
    "        self.columns_to_keep = [col for col in X.columns if col not in self.columns_to_remove]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.columns_to_keep]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a449b0bb",
   "metadata": {},
   "source": [
    "Zespół budowy stworzył funkcję 'show_scores' do wyświetlania metryk. Warto wiedzieć, że istnieje gotowa i importowana z 'sklearn.metrics' funkcja 'classification_report' służąca do tego samego.\n",
    "Minusem poniższej funkcji jest chociażby to, że nie każdy model przyjmuje metodę 'predict_proba'.\n",
    "Jeśli budujący używaliby takiego modelu jak np. MLPClassifier musieliby napisać drugą funkcję używającą metodę 'decision_function'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f688ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_scores(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    y_pred_prob = clf.predict_proba(X)\n",
    "    print(tabulate(confusion_matrix(y, y_pred), headers=['Predicted 0', 'Predicted 1'], tablefmt='orgtbl'))\n",
    "    print()\n",
    "    print(f'accuracy:              {round(accuracy_score(y, y_pred), 4)}')\n",
    "    print(f'precision:             {round(precision_score(y, y_pred), 4)}')\n",
    "    print(f'recall:                {round(recall_score(y, y_pred), 4)}')\n",
    "    print(f'f1:                    {round(f1_score(y, y_pred), 4)}')\n",
    "    print(f'roc_auc_discrete:      {round(roc_auc_score(y, y_pred), 4)}')\n",
    "    print(f'roc_auc_continuous:    {round(roc_auc_score(y, y_pred_prob[:, 1]), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9766580c",
   "metadata": {},
   "source": [
    "Przejdźmy zatem do modeli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b460917",
   "metadata": {},
   "source": [
    "# 3. Regresja logistyczna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2616b4",
   "metadata": {},
   "source": [
    "## 3.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9082c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kod zepołu budowy\n",
    "# zarówno dla zmiennych dyskretnych i ciągłych zaspół budowy stosuje transformator ColumnRemover z różnymi parametrami \n",
    "# w kolejnych krokach będzie szukać najlepszej ich kombinacji\n",
    "\n",
    "#hot encoding zmiennych dyskretnych - jako kategoryczne\n",
    "int_transformer = Pipeline([\n",
    "    ('int', ColumnRemover(0.9995, 0.99, 1)),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int64'))])\n",
    "\n",
    "#Zespół budowy upiera się że standaryzacja jest lepsza od normalizacji min-max dla tego modelu\n",
    "float_transformer = Pipeline([\n",
    "    ('float', ColumnRemover(0.9999, 0.99, 10)),\n",
    "    ('standard_scaler', StandardScaler())])\n",
    "\n",
    "col_transformer = ColumnTransformer([\n",
    "    ('int_pipe', int_transformer, make_column_selector(dtype_include=np.int64)),\n",
    "    ('float_pipe', float_transformer, make_column_selector(dtype_include=np.float64))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e5b4fb",
   "metadata": {},
   "source": [
    "## 3.2 Trening pierwszego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "064304af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('target', axis=1)\n",
    "y_train = train_df.target\n",
    "x_eval = eval_set.drop('target', axis=1)\n",
    "y_eval = eval_set.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87a05a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         23550 |            10 |\n",
      "|           934 |             6 |\n",
      "\n",
      "accuracy:              0.9615\n",
      "precision:             0.375\n",
      "recall:                0.0064\n",
      "f1:                    0.0126\n",
      "roc_auc_discrete:      0.503\n",
      "roc_auc_continuous:    0.8057\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('preprocessing', col_transformer),\n",
    "    ('model', LogisticRegression(random_state=42))])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# wyniki dla danych treningowych\n",
    "show_scores(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f192059f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         14391 |             8 |\n",
      "|           600 |             1 |\n",
      "\n",
      "accuracy:              0.9595\n",
      "precision:             0.1111\n",
      "recall:                0.0017\n",
      "f1:                    0.0033\n",
      "roc_auc_discrete:      0.5006\n",
      "roc_auc_continuous:    0.7864\n"
     ]
    }
   ],
   "source": [
    "# wyniki dla danych walidacyjnych \n",
    "show_scores(clf, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13cb920d",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "accuracy:              0.9556\n",
    "\n",
    "precision:             0.0556\n",
    "\n",
    "recall:                0.0022\n",
    "\n",
    "f1:                    0.0043\n",
    "\n",
    "roc_auc_discrete:      0.5003\n",
    "\n",
    "roc_auc_continuous:    0.7813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58a9cae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         16261 |          7299 |\n",
      "|           207 |           733 |\n",
      "\n",
      "accuracy:              0.6936\n",
      "precision:             0.0913\n",
      "recall:                0.7798\n",
      "f1:                    0.1634\n",
      "roc_auc_discrete:      0.735\n",
      "roc_auc_continuous:    0.8125\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('preprocessing', col_transformer),\n",
    "    ('model', LogisticRegression(random_state=42, class_weight='balanced'))])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "show_scores(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af1d54e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|          9873 |          4526 |\n",
      "|           163 |           438 |\n",
      "\n",
      "accuracy:              0.6874\n",
      "precision:             0.0882\n",
      "recall:                0.7288\n",
      "f1:                    0.1574\n",
      "roc_auc_discrete:      0.7072\n",
      "roc_auc_continuous:    0.7848\n"
     ]
    }
   ],
   "source": [
    "#wyniki dla danych walidacyjnych\n",
    "show_scores(clf, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e06967e6",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "accuracy:              0.683\n",
    "\n",
    "precision:             0.0932\n",
    "\n",
    "recall:                0.7333\n",
    "\n",
    "f1:                    0.1655\n",
    "\n",
    "roc_auc_discrete:      0.707\n",
    "\n",
    "roc_auc_continuous:    0.7784"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad52d6a8",
   "metadata": {},
   "source": [
    "### Minimalnie lepiej..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5120fc",
   "metadata": {},
   "source": [
    "## 3.3 Strojenie hiperparametrów i dobór cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f6af757",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('target', axis=1)\n",
    "y_train = train_df.target\n",
    "x_eval = eval_set.drop('target', axis=1)\n",
    "y_eval = eval_set.target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c58d1ea0",
   "metadata": {},
   "source": [
    "### 3.3.2 Regularyzacja modelu\n",
    "\n",
    "Zespół budowy pragnie zapobiec overfittingowi. \n",
    "\n",
    "Zajmuje się regularyzacją modelu regresji liniowej - będzie sprawdzać odwrotność współczynnika regularyzacji oraz rodzaj kary (l1, l2). Zastosują parametry ColumnRemovera ustalone w poprzednich podpunktach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80c1b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kod zespołu budowy\n",
    "#parametry ColumnRemovera na znalezione w 3.3.1\n",
    "int_transformer = Pipeline([\n",
    "    ('int', ColumnRemover(0.9998, 1, 0)),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int64'))])\n",
    "\n",
    "float_transformer = Pipeline([\n",
    "    ('float', ColumnRemover(0.9996, 0.97, 0)),\n",
    "    ('standard_scaler', StandardScaler())])\n",
    "\n",
    "col_transformer = ColumnTransformer([\n",
    "    ('int_pipe', int_transformer, make_column_selector(dtype_include=np.int64)),\n",
    "    ('float_pipe', float_transformer, make_column_selector(dtype_include=np.float64))\n",
    "])\n",
    "\n",
    "X_train = col_transformer.fit_transform(train_df.drop('target', axis=1), train_df.target)\n",
    "y_train = train_df.target\n",
    "x_eval = col_transformer.transform(eval_set.drop('target', axis=1))\n",
    "y_eval = eval_set.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4863de1",
   "metadata": {},
   "source": [
    "Sprawdzamy najlepsze parametry i wyniki dla najlepszego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59bfcfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7879 {'C': 0.11288378916846883, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "#Wyniki \n",
    "#reg_search.best_score_ = 0.7879, reg_search.best_params_ = {'C': 0.11288378916846883, 'penalty': 'l1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ff9e154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         16357 |          7203 |\n",
      "|           213 |           727 |\n",
      "\n",
      "accuracy:              0.6973\n",
      "precision:             0.0917\n",
      "recall:                0.7734\n",
      "f1:                    0.1639\n",
      "roc_auc_discrete:      0.7338\n",
      "roc_auc_continuous:    0.8121\n"
     ]
    }
   ],
   "source": [
    "#dla danych treningowych\n",
    "clf = LogisticRegression(random_state=42, class_weight='balanced', solver='liblinear', C=0.11288378916846883, penalty='l1')\n",
    "clf.fit(X_train, y_train)\n",
    "show_scores(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2172af91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|          9918 |          4481 |\n",
      "|           169 |           432 |\n",
      "\n",
      "accuracy:              0.69\n",
      "precision:             0.0879\n",
      "recall:                0.7188\n",
      "f1:                    0.1567\n",
      "roc_auc_discrete:      0.7038\n",
      "roc_auc_continuous:    0.7893\n"
     ]
    }
   ],
   "source": [
    "#dla danych walidacyjnych \n",
    "show_scores(clf, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4bbd94c4",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "accuracy:              0.6879\n",
    "\n",
    "precision:             0.0944\n",
    "\n",
    "recall:                0.7311\n",
    "\n",
    "f1:                    0.1672\n",
    "\n",
    "roc_auc_discrete:      0.7085\n",
    "\n",
    "roc_auc_continuous:    0.782"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0aefc062",
   "metadata": {},
   "source": [
    "### 3.3.3 Dobór zmiennych nie wymagajacy modelu\n",
    "\n",
    "Korelację uwzględnili w transformatorze ColumnRemover. Technika - SelectKBest. Najlepsze K zostało wybrane podczas Grid Searchu przez zespół budowy. Poniżej jest ostatecznie wybrana wartość dla najlepszego K zmiennych.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "712977ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         15821 |          7739 |\n",
      "|           231 |           709 |\n",
      "\n",
      "accuracy:              0.6747\n",
      "precision:             0.0839\n",
      "recall:                0.7543\n",
      "f1:                    0.151\n",
      "roc_auc_discrete:      0.7129\n",
      "roc_auc_continuous:    0.7852\n",
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|          9603 |          4796 |\n",
      "|           162 |           439 |\n",
      "\n",
      "accuracy:              0.6695\n",
      "precision:             0.0839\n",
      "recall:                0.7304\n",
      "f1:                    0.1504\n",
      "roc_auc_discrete:      0.6987\n",
      "roc_auc_continuous:    0.7713\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('select', SelectKBest(k=33)),\n",
    "    ('model', LogisticRegression(random_state=42, class_weight='balanced'))])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "show_scores(clf, X_train, y_train)\n",
    "show_scores(clf, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1166c15a",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "accuracy:              0.687\n",
    "\n",
    "precision:             0.0941\n",
    "\n",
    "recall:                0.7311\n",
    "\n",
    "f1:                    0.1668\n",
    "\n",
    "roc_auc_discrete:      0.708\n",
    "\n",
    "roc_auc_continuous:    0.7796"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0469602",
   "metadata": {},
   "source": [
    "### 3.3.4 Dobór zmiennych na podstawie modelu\n",
    "\n",
    "Dotychczasowe starania miały na celu osiągnięcie jak najlepszych rezultatów dla modelu. Teraz przeprowadzimy dobór cech na podstawie modelu ze znalezionymi najlepszymi parametrami. Zastosujemy metody L1-based feature selection, Sequential Feature Selection i RFE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1dfd6027",
   "metadata": {},
   "source": [
    "### SelectFromModel - L1-based feature selection\n",
    "Pozmiżej zastosowane parametry mają wartości wyselekcjonowane podczas Grid Searchu | 'C': 0.11288378916846883, 'penalty': 'l1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef551536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         16357 |          7203 |\n",
      "|           213 |           727 |\n",
      "\n",
      "accuracy:              0.6973\n",
      "precision:             0.0917\n",
      "recall:                0.7734\n",
      "f1:                    0.1639\n",
      "roc_auc_discrete:      0.7338\n",
      "roc_auc_continuous:    0.8121\n",
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|          9918 |          4481 |\n",
      "|           169 |           432 |\n",
      "\n",
      "accuracy:              0.69\n",
      "precision:             0.0879\n",
      "recall:                0.7188\n",
      "f1:                    0.1567\n",
      "roc_auc_discrete:      0.7038\n",
      "roc_auc_continuous:    0.7893\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, solver='liblinear', penalty='l1', C=0.11288378916846883, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "show_scores(clf, X_train, y_train)\n",
    "show_scores(clf, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5783fe65",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "accuracy:              0.6879\n",
    "\n",
    "precision:             0.0944\n",
    "\n",
    "recall:                0.7311\n",
    "\n",
    "f1:                    0.1672\n",
    "\n",
    "roc_auc_discrete:      0.7085\n",
    "\n",
    "roc_auc_continuous:    0.782"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d38d3446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ccf062c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfl = SelectFromModel(clf, prefit=True)\n",
    "X_train_t = sfl.transform(X_train)\n",
    "X_eval_t = sfl.transform(x_eval)\n",
    "X_train_t.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "141852ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         16357 |          7203 |\n",
      "|           213 |           727 |\n",
      "\n",
      "accuracy:              0.6973\n",
      "precision:             0.0917\n",
      "recall:                0.7734\n",
      "f1:                    0.1639\n",
      "roc_auc_discrete:      0.7338\n",
      "roc_auc_continuous:    0.8121\n",
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|          9918 |          4481 |\n",
      "|           169 |           432 |\n",
      "\n",
      "accuracy:              0.69\n",
      "precision:             0.0879\n",
      "recall:                0.7188\n",
      "f1:                    0.1567\n",
      "roc_auc_discrete:      0.7038\n",
      "roc_auc_continuous:    0.7893\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_t, y_train)\n",
    "\n",
    "show_scores(clf, X_train_t, y_train)\n",
    "show_scores(clf, X_eval_t, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "912e7faf",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "accuracy:              0.6879\n",
    "\n",
    "precision:             0.0944\n",
    "\n",
    "recall:                0.7311\n",
    "\n",
    "f1:                    0.1672\n",
    "\n",
    "roc_auc_discrete:      0.7085\n",
    "\n",
    "roc_auc_continuous:    0.7823\n",
    "\n",
    "Nie obserwujemy żadnego spadku w wynikach - zreudkowanoy natomiast liczbę cech do 114."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8d7adbd",
   "metadata": {},
   "source": [
    "### Podsumowanie\n",
    "\n",
    "Model regresji logistycznej działa przyzwoicie jak na warunki otrzymanego zbioru danych. Istotne wydaje się użycie parametry class_weight = 'balanced'. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1007a8",
   "metadata": {},
   "source": [
    "# 4. Drzewa decyzyjne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f296b3f",
   "metadata": {},
   "source": [
    "## 4.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8281ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kod zespołu budowy\n",
    "# zarówno dla zmiennych dyskretnych i ciągłych stosujemy nasz transformator ColumnRemover z różnymi parametrami - w kolejnych krokach będziemy szukać najlepszej ich kombinacji\n",
    "\n",
    "# dokonujemy kodowania one hot encoding zmiennych dyskretnych - traktujemy je jako kategoryczne\n",
    "int_transformer = Pipeline([\n",
    "    ('int', ColumnRemover(0.9995, 0.99, 1)),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int64'))])\n",
    "\n",
    "# jesteśmy przy drzewach decyzyjnych, więc nie musimy skalować cech\n",
    "float_transformer = Pipeline([\n",
    "    ('float', ColumnRemover(0.9999, 0.99, 10))])\n",
    "\n",
    "col_transformer = ColumnTransformer([\n",
    "    ('int_pipe', int_transformer, make_column_selector(dtype_include=np.int64)),\n",
    "    ('float_pipe', float_transformer, make_column_selector(dtype_include=np.float64))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c0503",
   "metadata": {},
   "source": [
    "## 4.2 Trening pierwszego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "901fb3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('target', axis=1)\n",
    "y_train = train_df.target\n",
    "x_eval = eval_set.drop('target', axis=1)\n",
    "y_eval = eval_set.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12ad30d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         23560 |             0 |\n",
      "|             3 |           937 |\n",
      "\n",
      "accuracy:              0.9999\n",
      "precision:             1.0\n",
      "recall:                0.9968\n",
      "f1:                    0.9984\n",
      "roc_auc_discrete:      0.9984\n",
      "roc_auc_continuous:    1.0\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('preprocessing', col_transformer),\n",
    "    ('model', DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "show_scores(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "902dcaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         13807 |           592 |\n",
      "|           503 |            98 |\n",
      "\n",
      "accuracy:              0.927\n",
      "precision:             0.142\n",
      "recall:                0.1631\n",
      "f1:                    0.1518\n",
      "roc_auc_discrete:      0.561\n",
      "roc_auc_continuous:    0.5609\n"
     ]
    }
   ],
   "source": [
    "show_scores(clf, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8eadccff",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "ccuracy:              0.9257\n",
    "\n",
    "precision:             0.1429\n",
    "\n",
    "recall:                0.1467\n",
    "\n",
    "f1:                    0.1447\n",
    "\n",
    "roc_auc_discrete:      0.5536\n",
    "\n",
    "roc_auc_continuous:    0.5536"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5a01e",
   "metadata": {},
   "source": [
    "Model jest zdecydowanie przeuczony. Spróbujmy z parametrem class_weight='balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d544b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         23557 |             3 |\n",
      "|             0 |           940 |\n",
      "\n",
      "accuracy:              0.9999\n",
      "precision:             0.9968\n",
      "recall:                1.0\n",
      "f1:                    0.9984\n",
      "roc_auc_discrete:      0.9999\n",
      "roc_auc_continuous:    1.0\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('preprocessing', col_transformer),\n",
    "    ('model', DecisionTreeClassifier(random_state=42, class_weight='balanced'))])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "show_scores(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5977723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         13855 |           544 |\n",
      "|           529 |            72 |\n",
      "\n",
      "accuracy:              0.9285\n",
      "precision:             0.1169\n",
      "recall:                0.1198\n",
      "f1:                    0.1183\n",
      "roc_auc_discrete:      0.541\n",
      "roc_auc_continuous:    0.541\n"
     ]
    }
   ],
   "source": [
    "show_scores(clf, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e46b9190",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "accuracy:              0.9291\n",
    "\n",
    "precision:             0.1288\n",
    "\n",
    "recall:                0.1133\n",
    "\n",
    "f1:                    0.1206\n",
    "\n",
    "roc_auc_discrete:      0.5395\n",
    "\n",
    "roc_auc_continuous:    0.5395"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c47df57e",
   "metadata": {},
   "source": [
    "Za dużo to nie dało"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d83c761",
   "metadata": {},
   "source": [
    "## 4.3 Strojenie hiperparametrów i wybór zmiennych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b1cb1",
   "metadata": {},
   "source": [
    "### 4.3.1 Dobór parametrów dla ColumnRemover'a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9149f4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5594 {'preprocessing__int_pipe__int__threshold_corr': 0.99, 'preprocessing__int_pipe__int__threshold_constant': 0.9998, 'preprocessing__int_pipe__int__n_info_vals': 2, 'preprocessing__float_pipe__float__threshold_corr': 0.96, 'preprocessing__float_pipe__float__threshold_constant': 0.9998, 'preprocessing__float_pipe__float__n_info_vals': 15}\n"
     ]
    }
   ],
   "source": [
    "#Parametry dla narzędzia autorstwa zespołu budowy \n",
    "#col_remove_search.best_score_ = 0.5594\n",
    "            \n",
    "# col_remove_search.best_params_\n",
    "#  {'preprocessing__int_pipe__int__threshold_corr': 0.99, 'preprocessing__int_pipe__int__threshold_constant': 0.9998,\n",
    "#   'preprocessing__int_pipe__int__n_info_vals': 2, 'preprocessing__float_pipe__float__threshold_corr': 0.96,\n",
    "#   'preprocessing__float_pipe__float__threshold_constant': 0.9998, 'preprocessing__float_pipe__float__n_info_vals': 15}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8891fa65",
   "metadata": {},
   "source": [
    "### 4.3.2 Regularyzacja modelu\n",
    "\n",
    "Zajmiemy się regularyzacją modelu drzewa decyzyjnego - będziemy sprawdzać parametry max_depth, min_samples_split, min_samples_leaf, max_features. Na początek jednak skupimy się tylko na max_depth - być może z jego powodu drzewo jest tak mocno przeuczone. Zastosujemy również najlepsze parametry ColumnRemovera znalezione w poprzednim podpunkcie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "625a9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_transformer = Pipeline([\n",
    "    ('int', ColumnRemover(0.9998, 0.99, 2)),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int64'))])\n",
    "\n",
    "float_transformer = Pipeline([\n",
    "    ('float', ColumnRemover(0.9998, 0.96, 15))])\n",
    "\n",
    "col_transformer = ColumnTransformer([\n",
    "    ('int_pipe', int_transformer, make_column_selector(dtype_include=np.int64)),\n",
    "    ('float_pipe', float_transformer, make_column_selector(dtype_include=np.float64))\n",
    "])\n",
    "\n",
    "# od tej pory dane testowe i treningowe będą już wstępnie przeprocesowane\n",
    "X_train = col_transformer.fit_transform(train_df.drop('target', axis=1), train_df.target)\n",
    "y_train = train_df.target\n",
    "x_eval = col_transformer.transform(eval_set.drop('target', axis=1))\n",
    "y_eval = eval_set.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d392324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wynik GridSearchu z metryką roc_auc\n",
    "# depth_search.best_params_={'max_depth': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05b0b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         23557 |             3 |\n",
      "|           925 |            15 |\n",
      "\n",
      "accuracy:              0.9621\n",
      "precision:             0.8333\n",
      "recall:                0.016\n",
      "f1:                    0.0313\n",
      "roc_auc_discrete:      0.5079\n",
      "roc_auc_continuous:    0.8135\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42, max_depth=4)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "show_scores(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd4b49bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         14387 |            12 |\n",
      "|           601 |             0 |\n",
      "\n",
      "accuracy:              0.9591\n",
      "precision:             0.0\n",
      "recall:                0.0\n",
      "f1:                    0.0\n",
      "roc_auc_discrete:      0.4996\n",
      "roc_auc_continuous:    0.8066\n"
     ]
    }
   ],
   "source": [
    "show_scores(clf, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f0f863c",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "accuracy:              0.9562\n",
    "\n",
    "precision:             0.0\n",
    "\n",
    "recall:                0.0\n",
    "\n",
    "f1:                    0.0\n",
    "\n",
    "roc_auc_discrete:      0.4995\n",
    "\n",
    "roc_auc_continuous:    0.7994"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c71b44dc",
   "metadata": {},
   "source": [
    "Dość podejrzane te wyniki. Sprawdźmy z metrykę f1 w GridSearchu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2937150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wynik z f1\n",
    "#depth_search.best_params_={'max_depth': 29}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c29d03e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         23546 |            14 |\n",
      "|            29 |           911 |\n",
      "\n",
      "accuracy:              0.9982\n",
      "precision:             0.9849\n",
      "recall:                0.9691\n",
      "f1:                    0.9769\n",
      "roc_auc_discrete:      0.9843\n",
      "roc_auc_continuous:    0.9999\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42, max_depth=29)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "show_scores(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "525a6176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         13804 |           595 |\n",
      "|           498 |           103 |\n",
      "\n",
      "accuracy:              0.9271\n",
      "precision:             0.1476\n",
      "recall:                0.1714\n",
      "f1:                    0.1586\n",
      "roc_auc_discrete:      0.565\n",
      "roc_auc_continuous:    0.5699\n"
     ]
    }
   ],
   "source": [
    "show_scores(clf, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "725014ed",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "accuracy:              0.925\n",
    "\n",
    "precision:             0.1497\n",
    "\n",
    "recall:                0.16\n",
    "\n",
    "f1:                    0.1547\n",
    "\n",
    "roc_auc_discrete:      0.5597\n",
    "\n",
    "roc_auc_continuous:    0.5665"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d4e1de5",
   "metadata": {},
   "source": [
    "Sprawdzamy najlepszą kombinację f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e9390b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1182 {'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 125, 'max_depth': 25}\n"
     ]
    }
   ],
   "source": [
    "#rand_search.best_params_={'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 125, 'max_depth': 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73c3bd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         23394 |           166 |\n",
      "|           439 |           501 |\n",
      "\n",
      "accuracy:              0.9753\n",
      "precision:             0.7511\n",
      "recall:                0.533\n",
      "f1:                    0.6235\n",
      "roc_auc_discrete:      0.763\n",
      "roc_auc_continuous:    0.9878\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42, max_depth=25, min_samples_split=3, min_samples_leaf=3, max_features=125)\n",
    "clf.fit(X_train, y_train)\n",
    "show_scores(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ececad1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         14041 |           358 |\n",
      "|           524 |            77 |\n",
      "\n",
      "accuracy:              0.9412\n",
      "precision:             0.177\n",
      "recall:                0.1281\n",
      "f1:                    0.1486\n",
      "roc_auc_discrete:      0.5516\n",
      "roc_auc_continuous:    0.6043\n"
     ]
    }
   ],
   "source": [
    "show_scores(clf, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dfa57d4",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "accuracy:              0.936\n",
    "\n",
    "precision:             0.1553\n",
    "\n",
    "recall:                0.1111\n",
    "\n",
    "f1:                    0.1295\n",
    "\n",
    "roc_auc_discrete:      0.542\n",
    "\n",
    "roc_auc_continuous:    0.5879"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "deb82bca",
   "metadata": {},
   "source": [
    "Stosowane zabiegi na drzewach nie przyniosły zancznej poprawy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d1c06d6",
   "metadata": {},
   "source": [
    "### 4.3.3 Dobór zmiennych nie wymagajacy modelu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab8062",
   "metadata": {},
   "source": [
    "### SelectKBest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7634a752",
   "metadata": {},
   "source": [
    "metryka f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a067f48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         23560 |             0 |\n",
      "|            15 |           925 |\n",
      "\n",
      "accuracy:              0.9994\n",
      "precision:             1.0\n",
      "recall:                0.984\n",
      "f1:                    0.992\n",
      "roc_auc_discrete:      0.992\n",
      "roc_auc_continuous:    1.0\n",
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         13761 |           638 |\n",
      "|           516 |            85 |\n",
      "\n",
      "accuracy:              0.9231\n",
      "precision:             0.1176\n",
      "recall:                0.1414\n",
      "f1:                    0.1284\n",
      "roc_auc_discrete:      0.5486\n",
      "roc_auc_continuous:    0.5481\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('select', SelectKBest(k=106)),\n",
    "    ('model', DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "show_scores(clf, X_train, y_train)\n",
    "show_scores(clf, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2566b38a",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "accuracy:              0.9239\n",
    "\n",
    "precision:             0.1531\n",
    "\n",
    "recall:                0.1711\n",
    "\n",
    "f1:                    0.1616\n",
    "\n",
    "roc_auc_discrete:      0.5644\n",
    "\n",
    "roc_auc_continuous:    0.565"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b78d1",
   "metadata": {},
   "source": [
    "### 4.3.4 Dobór zmiennych na podstawie modelu\n",
    "\n",
    "Przeprowadzimy dobór cech na podstawie modelu ze znalezionymi najlepszymi parametrami. Zastosujemy metody SelectFromModel - feature importance, Sequential Feature Selection i RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bea262",
   "metadata": {},
   "source": [
    "### SelectFromModel - tree-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2a3707e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         23560 |             0 |\n",
      "|             3 |           937 |\n",
      "\n",
      "accuracy:              0.9999\n",
      "precision:             1.0\n",
      "recall:                0.9968\n",
      "f1:                    0.9984\n",
      "roc_auc_discrete:      0.9984\n",
      "roc_auc_continuous:    1.0\n",
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         13805 |           594 |\n",
      "|           497 |           104 |\n",
      "\n",
      "accuracy:              0.9273\n",
      "precision:             0.149\n",
      "recall:                0.173\n",
      "f1:                    0.1601\n",
      "roc_auc_discrete:      0.5659\n",
      "roc_auc_continuous:    0.5658\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "show_scores(clf, X_train, y_train)\n",
    "show_scores(clf, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "765d504e",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "accuracy:              0.9261\n",
    "\n",
    "precision:             0.1517\n",
    "\n",
    "recall:                0.1578\n",
    "\n",
    "f1:                    0.1547\n",
    "\n",
    "roc_auc_discrete:      0.5591\n",
    "\n",
    "roc_auc_continuous:    0.5591"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "053a9d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c22f9615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfl = SelectFromModel(clf, prefit=True)\n",
    "X_train_t = sfl.transform(X_train)\n",
    "X_eval_t = sfl.transform(x_eval)\n",
    "X_train_t.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01058e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         23560 |             0 |\n",
      "|             3 |           937 |\n",
      "\n",
      "accuracy:              0.9999\n",
      "precision:             1.0\n",
      "recall:                0.9968\n",
      "f1:                    0.9984\n",
      "roc_auc_discrete:      0.9984\n",
      "roc_auc_continuous:    1.0\n",
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         13771 |           628 |\n",
      "|           489 |           112 |\n",
      "\n",
      "accuracy:              0.9255\n",
      "precision:             0.1514\n",
      "recall:                0.1864\n",
      "f1:                    0.167\n",
      "roc_auc_discrete:      0.5714\n",
      "roc_auc_continuous:    0.5712\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_t, y_train)\n",
    "\n",
    "show_scores(clf, X_train_t, y_train)\n",
    "show_scores(clf, X_eval_t, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b105ed1e",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "accuracy:              0.9211\n",
    "\n",
    "precision:             0.1337\n",
    "\n",
    "recall:                0.1533\n",
    "\n",
    "f1:                    0.1429\n",
    "\n",
    "roc_auc_discrete:      0.5544\n",
    "\n",
    "roc_auc_continuous:    0.5544"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "377e0d5f",
   "metadata": {},
   "source": [
    "Powyższy wynik jest przy 22 cechach, natomiast wyniki metryk są pogorszone."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f057921c",
   "metadata": {},
   "source": [
    "### 4.4 Podsumowanie\n",
    "\n",
    "Model drzewa decyzyjnego działa bardzo słabo w przypadku tego zbioru danych. Ma tendencje do overfittingu. Nie jesteśmy w stanie nic z tym zrobić. \n",
    "\n",
    "Natomiast redukcja zmiennych:\n",
    "- SelectKBest - 106\n",
    "- Tree-based feature selection (feature_importance) - 22\n",
    "\n",
    "Zespół budowy słusznie zauważa duże znaczenie parametru feature importance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490f1f3",
   "metadata": {},
   "source": [
    "# 5. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cd86a2",
   "metadata": {},
   "source": [
    "## 5.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b34d5909",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_transformer = Pipeline([\n",
    "    ('int', ColumnRemover(0.9995, 0.99, 1)),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int64'))])\n",
    "\n",
    "float_transformer = Pipeline([\n",
    "    ('float', ColumnRemover(0.9999, 0.99, 10)),\n",
    "    ('standard_scaler', StandardScaler())])\n",
    "\n",
    "col_transformer = ColumnTransformer([\n",
    "    ('int_pipe', int_transformer, make_column_selector(dtype_include=np.int64)),\n",
    "    ('float_pipe', float_transformer, make_column_selector(dtype_include=np.float64))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "473de74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('target', axis=1)\n",
    "y_train = train_df.target\n",
    "x_eval = eval_set.drop('target', axis=1)\n",
    "y_eval = eval_set.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af085295",
   "metadata": {},
   "source": [
    "## 5.2 Trening pierwszego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b52161f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         23560 |             0 |\n",
      "|           926 |            14 |\n",
      "\n",
      "accuracy:              0.9622\n",
      "precision:             1.0\n",
      "recall:                0.0149\n",
      "f1:                    0.0294\n",
      "roc_auc_discrete:      0.5074\n",
      "roc_auc_continuous:    0.8062\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('preprocessing', col_transformer),\n",
    "    ('model', SVC(random_state=42, probability=True))])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "show_scores(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19c9ce94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         14399 |             0 |\n",
      "|           601 |             0 |\n",
      "\n",
      "accuracy:              0.9599\n",
      "precision:             0.0\n",
      "recall:                0.0\n",
      "f1:                    0.0\n",
      "roc_auc_discrete:      0.5\n",
      "roc_auc_continuous:    0.6425\n"
     ]
    }
   ],
   "source": [
    "#wyniki dla zbioru walidacyjnego\n",
    "show_scores(clf, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f405da9",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "accuracy:              0.9571\n",
    "\n",
    "precision:             0.0\n",
    "\n",
    "recall:                0.0\n",
    "\n",
    "f1:                    0.0\n",
    "\n",
    "roc_auc_discrete:      0.5\n",
    "\n",
    "roc_auc_continuous:    0.494\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83466c90",
   "metadata": {},
   "source": [
    "### Podsumowująć Support Vector Machine się nie nadaje "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a661e",
   "metadata": {},
   "source": [
    "# 6. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a46715",
   "metadata": {},
   "source": [
    "## 6.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7e53fb7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "int_transformer = Pipeline([\n",
    "    ('int', ColumnRemover(0.9995, 0.99, 1)),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int64'))])\n",
    "\n",
    "float_transformer = Pipeline([\n",
    "    ('float', ColumnRemover(0.9999, 0.99, 10))])\n",
    "\n",
    "col_transformer = ColumnTransformer([\n",
    "    ('int_pipe', int_transformer, make_column_selector(dtype_include=np.int64)),\n",
    "    ('float_pipe', float_transformer, make_column_selector(dtype_include=np.float64))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c6f0c",
   "metadata": {},
   "source": [
    "## 6.2 Trening modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b1f4c90",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_train = train_df.drop('target', axis=1)\n",
    "y_train = train_df.target\n",
    "x_eval = eval_set.drop('target', axis=1)\n",
    "y_eval = eval_set.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "646a572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         23560 |             0 |\n",
      "|             3 |           937 |\n",
      "\n",
      "accuracy:              0.9999\n",
      "precision:             1.0\n",
      "recall:                0.9968\n",
      "f1:                    0.9984\n",
      "roc_auc_discrete:      0.9984\n",
      "roc_auc_continuous:    1.0\n",
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         14369 |            30 |\n",
      "|           589 |            12 |\n",
      "\n",
      "accuracy:              0.9587\n",
      "precision:             0.2857\n",
      "recall:                0.02\n",
      "f1:                    0.0373\n",
      "roc_auc_discrete:      0.5089\n",
      "roc_auc_continuous:    0.8047\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42, n_estimators=1000)\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('preprocessing', col_transformer),\n",
    "    ('model', rf)])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "show_scores(clf, X_train, y_train)\n",
    "show_scores(clf, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdd57648",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "accuracy:              0.9557\n",
    "\n",
    "precision:             0.2414\n",
    "\n",
    "recall:                0.0156\n",
    "\n",
    "f1:                    0.0292\n",
    "\n",
    "roc_auc_discrete:      0.5067\n",
    "\n",
    "roc_auc_continuous:    0.7948\n",
    "\n",
    "### Zespół przeczucza las losowy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e58df5b9",
   "metadata": {},
   "source": [
    "# Próba z parametrami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d0a695c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         23560 |             0 |\n",
      "|           784 |           156 |\n",
      "\n",
      "accuracy:              0.968\n",
      "precision:             1.0\n",
      "recall:                0.166\n",
      "f1:                    0.2847\n",
      "roc_auc_discrete:      0.583\n",
      "roc_auc_continuous:    0.9986\n",
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         14396 |             3 |\n",
      "|           601 |             0 |\n",
      "\n",
      "accuracy:              0.9597\n",
      "precision:             0.0\n",
      "recall:                0.0\n",
      "f1:                    0.0\n",
      "roc_auc_discrete:      0.4999\n",
      "roc_auc_continuous:    0.8239\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42, n_estimators=1000, min_samples_split=3, min_samples_leaf=3, max_features=125, max_depth=25)\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('preprocessing', col_transformer),\n",
    "    ('model', rf)])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "show_scores(clf, X_train, y_train)\n",
    "show_scores(clf, x_eval, y_eval)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de0654ca",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "accuracy:              0.9571\n",
    "\n",
    "precision:             0.0\n",
    "\n",
    "recall:                0.0\n",
    "\n",
    "f1:                    0.0\n",
    "\n",
    "roc_auc_discrete:      0.5\n",
    "\n",
    "roc_auc_continuous:    0.8218\n",
    "\n",
    "### Wniosek: las losowy również się nie nadaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19deb24a",
   "metadata": {},
   "source": [
    "# 7. Voting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb4d833c",
   "metadata": {},
   "source": [
    "\n",
    "Zespół budowy słusznie wybiera najlepsze modele, które wezmą udział w votingu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3676fde2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "log_reg_vc = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('int_pipe', Pipeline([\n",
    "            ('int', ColumnRemover(0.9998, 1, 0)),\n",
    "            ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int64'))]), make_column_selector(dtype_include=np.int64)),\n",
    "        ('float_pipe', Pipeline([\n",
    "            ('float', ColumnRemover(0.9996, 0.97, 0)),\n",
    "            ('standardization', StandardScaler())]), make_column_selector(dtype_include=np.float64))\n",
    "    ])),\n",
    "    ('selector', SelectKBest(k=33)),\n",
    "    ('model', LogisticRegression(random_state=42, class_weight='balanced'))])\n",
    "\n",
    "dct_vc = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('int_pipe', Pipeline([\n",
    "            ('int', ColumnRemover(0.9998, 0.99, 2)),\n",
    "            ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int64'))]), make_column_selector(dtype_include=np.int64)),\n",
    "        ('float_pipe', Pipeline([\n",
    "            ('float', ColumnRemover(0.9998, 0.96, 15)),\n",
    "            ]), make_column_selector(dtype_include=np.float64))\n",
    "    ])),\n",
    "    ('selector', SelectFromModel(DecisionTreeClassifier(random_state=42))),\n",
    "    ('model', DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "svc_vc = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('int_pipe', Pipeline([\n",
    "            ('int', ColumnRemover(0.9995, 0.99, 1)),\n",
    "            ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int64'))]), make_column_selector(dtype_include=np.int64)),\n",
    "        ('float_pipe', Pipeline([\n",
    "            ('float', ColumnRemover(0.9999, 0.99, 10)),\n",
    "            ('standard_scaler', StandardScaler())]), make_column_selector(dtype_include=np.float64))\n",
    "    ])),\n",
    "    ('model', SVC(random_state=42, probability=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f97a2fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m estimators\u001b[39m=\u001b[39m[(\u001b[39m'\u001b[39m\u001b[39mDecisionTree\u001b[39m\u001b[39m'\u001b[39m, dct_vc), (\u001b[39m'\u001b[39m\u001b[39mSVM\u001b[39m\u001b[39m'\u001b[39m, svc_vc), (\u001b[39m'\u001b[39m\u001b[39mLR\u001b[39m\u001b[39m'\u001b[39m, log_reg_vc)]\n\u001b[1;32m----> 2\u001b[0m vc \u001b[39m=\u001b[39m VotingClassifier(estimators\u001b[39m=\u001b[39;49mestimators, voting\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msoft\u001b[39;49m\u001b[39m'\u001b[39;49m, weights\u001b[39m=\u001b[39;49m[\u001b[39m0.2\u001b[39;49m, \u001b[39m0.1\u001b[39;49m, \u001b[39m0.7\u001b[39;49m])\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:346\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mle_\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m    344\u001b[0m transformed_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mle_\u001b[39m.\u001b[39mtransform(y)\n\u001b[1;32m--> 346\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, transformed_y, sample_weight)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:81\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators):\n\u001b[0;32m     76\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     77\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     78\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)\u001b[39m}\u001b[39;00m\u001b[39m weights, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators)\u001b[39m}\u001b[39;00m\u001b[39m estimators\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m     )\n\u001b[1;32m---> 81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m     82\u001b[0m     delayed(_fit_single_estimator)(\n\u001b[0;32m     83\u001b[0m         clone(clf),\n\u001b[0;32m     84\u001b[0m         X,\n\u001b[0;32m     85\u001b[0m         y,\n\u001b[0;32m     86\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m     87\u001b[0m         message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mVoting\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     88\u001b[0m         message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(names[idx], idx \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, \u001b[39mlen\u001b[39;49m(clfs)),\n\u001b[0;32m     89\u001b[0m     )\n\u001b[0;32m     90\u001b[0m     \u001b[39mfor\u001b[39;49;00m idx, clf \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(clfs)\n\u001b[0;32m     91\u001b[0m     \u001b[39mif\u001b[39;49;00m clf \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdrop\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     92\u001b[0m )\n\u001b[0;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnamed_estimators_ \u001b[39m=\u001b[39m Bunch()\n\u001b[0;32m     96\u001b[0m \u001b[39m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\parallel.py:1048\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1040\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1048\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    783\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\ensemble\\_base.py:46\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[1;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m---> 46\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[0;32m     47\u001b[0m \u001b[39mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[0;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    360\u001b[0m     cloned_transformer,\n\u001b[0;32m    361\u001b[0m     X,\n\u001b[0;32m    362\u001b[0m     y,\n\u001b[0;32m    363\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    365\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[0;32m    366\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:727\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_column_callables(X)\n\u001b[0;32m    725\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m--> 727\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_transform(X, y, _fit_transform_one)\n\u001b[0;32m    729\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result:\n\u001b[0;32m    730\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:658\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    652\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m    653\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(\n\u001b[0;32m    654\u001b[0m         fitted\u001b[39m=\u001b[39mfitted, replace_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    655\u001b[0m     )\n\u001b[0;32m    656\u001b[0m )\n\u001b[0;32m    657\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 658\u001b[0m     \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m    659\u001b[0m         delayed(func)(\n\u001b[0;32m    660\u001b[0m             transformer\u001b[39m=\u001b[39;49mclone(trans) \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m fitted \u001b[39melse\u001b[39;49;00m trans,\n\u001b[0;32m    661\u001b[0m             X\u001b[39m=\u001b[39;49m_safe_indexing(X, column, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m    662\u001b[0m             y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    663\u001b[0m             weight\u001b[39m=\u001b[39;49mweight,\n\u001b[0;32m    664\u001b[0m             message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mColumnTransformer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    665\u001b[0m             message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(name, idx, \u001b[39mlen\u001b[39;49m(transformers)),\n\u001b[0;32m    666\u001b[0m         )\n\u001b[0;32m    667\u001b[0m         \u001b[39mfor\u001b[39;49;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(transformers, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    668\u001b[0m     )\n\u001b[0;32m    669\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    670\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\parallel.py:1048\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1040\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1048\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    783\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\pipeline.py:437\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \n\u001b[0;32m    412\u001b[0m \u001b[39mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[39m    Transformed samples.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    436\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 437\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[0;32m    439\u001b[0m last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\n\u001b[0;32m    440\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    360\u001b[0m     cloned_transformer,\n\u001b[0;32m    361\u001b[0m     X,\n\u001b[0;32m    362\u001b[0m     y,\n\u001b[0;32m    363\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    365\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[0;32m    366\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\base.py:881\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "Cell \u001b[1;32mIn[11], line 36\u001b[0m, in \u001b[0;36mColumnRemover.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m# usuwanie kolumn nie niosących informacji\u001b[39;00m\n\u001b[0;32m     35\u001b[0m amount_of_ones \u001b[39m=\u001b[39m y[y \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 36\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mjoin(y)\n\u001b[0;32m     37\u001b[0m \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m X\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m     38\u001b[0m     tmp \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mgroupby(column)[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39magg([\u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39msort_values(\u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m,ascending \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mreset_index()\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\pandas\\core\\frame.py:9979\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[0;32m   9816\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(\n\u001b[0;32m   9817\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9818\u001b[0m     other: DataFrame \u001b[39m|\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[DataFrame \u001b[39m|\u001b[39m Series],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9824\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   9825\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m   9826\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   9827\u001b[0m \u001b[39m    Join columns of another DataFrame.\u001b[39;00m\n\u001b[0;32m   9828\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9977\u001b[0m \u001b[39m    5  K1  A5   B1\u001b[39;00m\n\u001b[0;32m   9978\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 9979\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_join_compat(\n\u001b[0;32m   9980\u001b[0m         other,\n\u001b[0;32m   9981\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m   9982\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m   9983\u001b[0m         lsuffix\u001b[39m=\u001b[39;49mlsuffix,\n\u001b[0;32m   9984\u001b[0m         rsuffix\u001b[39m=\u001b[39;49mrsuffix,\n\u001b[0;32m   9985\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   9986\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m   9987\u001b[0m     )\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\pandas\\core\\frame.py:10046\u001b[0m, in \u001b[0;36mDataFrame._join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[0;32m  10040\u001b[0m \u001b[39m# Mypy thinks the RHS is a\u001b[39;00m\n\u001b[0;32m  10041\u001b[0m \u001b[39m# \"Union[DataFrame, Series, Iterable[Union[DataFrame, Series]]]\" whereas\u001b[39;00m\n\u001b[0;32m  10042\u001b[0m \u001b[39m# the LHS is an \"Iterable[DataFrame]\", but in reality both types are\u001b[39;00m\n\u001b[0;32m  10043\u001b[0m \u001b[39m# \"Iterable[Union[DataFrame, Series]]\" due to the if statements\u001b[39;00m\n\u001b[0;32m  10044\u001b[0m frames \u001b[39m=\u001b[39m [cast(\u001b[39m\"\u001b[39m\u001b[39mDataFrame | Series\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m)] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(other)\n\u001b[1;32m> 10046\u001b[0m can_concat \u001b[39m=\u001b[39m \u001b[39mall\u001b[39;49m(df\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mis_unique \u001b[39mfor\u001b[39;49;00m df \u001b[39min\u001b[39;49;00m frames)\n\u001b[0;32m  10048\u001b[0m \u001b[39m# join indexes only using concat\u001b[39;00m\n\u001b[0;32m  10049\u001b[0m \u001b[39mif\u001b[39;00m can_concat:\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\pandas\\core\\frame.py:10046\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m  10040\u001b[0m \u001b[39m# Mypy thinks the RHS is a\u001b[39;00m\n\u001b[0;32m  10041\u001b[0m \u001b[39m# \"Union[DataFrame, Series, Iterable[Union[DataFrame, Series]]]\" whereas\u001b[39;00m\n\u001b[0;32m  10042\u001b[0m \u001b[39m# the LHS is an \"Iterable[DataFrame]\", but in reality both types are\u001b[39;00m\n\u001b[0;32m  10043\u001b[0m \u001b[39m# \"Iterable[Union[DataFrame, Series]]\" due to the if statements\u001b[39;00m\n\u001b[0;32m  10044\u001b[0m frames \u001b[39m=\u001b[39m [cast(\u001b[39m\"\u001b[39m\u001b[39mDataFrame | Series\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m)] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(other)\n\u001b[1;32m> 10046\u001b[0m can_concat \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m(df\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39mis_unique \u001b[39mfor\u001b[39;00m df \u001b[39min\u001b[39;00m frames)\n\u001b[0;32m  10048\u001b[0m \u001b[39m# join indexes only using concat\u001b[39;00m\n\u001b[0;32m  10049\u001b[0m \u001b[39mif\u001b[39;00m can_concat:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "estimators=[('DecisionTree', dct_vc), ('SVM', svc_vc), ('LR', log_reg_vc)]\n",
    "vc = VotingClassifier(estimators=estimators, voting='soft', weights=[0.2, 0.1, 0.7]).fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68d4f7d1",
   "metadata": {},
   "source": [
    "# Powyższa funkcja zwraca AttributeError : 'numpy.int64' object has no attribute 'index'\n",
    "### Problem powstaje przy fitowaniu danych\n",
    " notebook wykonywany jest poprawnie jednak przez wiele godzin nie można było znaleść przyczyny błędy\n",
    " sprawdzaliśmy wymiarowość oraz typ danych wchodzących do metody .fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "57d9e1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf1 <class 'sklearn.pipeline.Pipeline'>\n",
      "clf2 <class 'sklearn.pipeline.Pipeline'>\n",
      "clf3 <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "#walidacja: sprawdzam error \n",
    "eestimators = [('clf1', dct_vc), ('clf2', svc_vc), ('clf3', log_reg_vc)]\n",
    "\n",
    "for name, estimator in eestimators:\n",
    "    print(name, type(estimator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca928396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train is a 2D data frame\n",
      "y_train is a 1D Series\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#waliadacja: sprawdzam error\n",
    "if isinstance(X_train, (pd.DataFrame)) and X_train.ndim == 2:\n",
    "    print('X_train is a 2D data frame')\n",
    "else:\n",
    "    print('X_train is not a 2D data frame')\n",
    "\n",
    "if isinstance(y_train, (pd.Series)) and y_train.ndim == 1:\n",
    "    print('y_train is a 1D Series')\n",
    "else:\n",
    "    print('y_train is not a 1D Series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "73fdec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "#walidacja: sprawdzam error\n",
    "print(y_train.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "312bb03c",
   "metadata": {},
   "source": [
    " Przykłady rozwiązań tego problemu, które udało się znaleść przekopując internet dotyczyły niespełnienia któregoś z powyższych warunków, które zostały wyprintowane.\n",
    "\n",
    " Chat gpt również zawiódł, sugerował że problem z typem danych i nie powiedział nic czego byśmy nie sprawdzili żeby to później się zapętlić i wkoło opowiadać te same rozwiązania (które nie działały bo tylko na tym został wytrenowany).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Rozwiązanie problemu:\n",
    " Okazało się, że AttributeError pojawiający się przy .fit() wynika z błędnego napisania klasy 'ColumnRemover'.\n",
    " Aby poprawnie przeprowadzić voting należałoby zakomentować część tej klasy i dopiero później odpalić voting.\n",
    " Zespół budowy nie umieścił żadnej informacji na ten temat, a wystarczyłby komentarz nad kodem.\n",
    "\n",
    "\n",
    "\n",
    "### Wnioski:\n",
    " Winowającą okazała się część funkcji z klasy ColumnRemover, która była odpowiedzialna za usunięcie kolum nie niosących informacji.\n",
    " Pisanie własnych, skomplikowanych funkcji przetwarzących dane, a szczególnie takie nierzeczywiste jest ciężkim zadaniem. Prościej jest korzystać z gotowych rozwiązań. Obniża to możliwość pojawienia się nieprawidłowości.\n",
    " Ważne jest również komentowanie kodu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "40e579b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[('DecisionTree', dct_vc), ('SVM', svc_vc), ('LR', log_reg_vc)]\n",
    "vc = VotingClassifier(estimators=estimators, voting='soft', weights=[0.2, 0.1, 0.7]).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a4fd6a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         21395 |          2165 |\n",
      "|           179 |           761 |\n",
      "\n",
      "accuracy:              0.9043\n",
      "precision:             0.2601\n",
      "recall:                0.8096\n",
      "f1:                    0.3937\n",
      "roc_auc_discrete:      0.8588\n",
      "roc_auc_continuous:    0.9449\n"
     ]
    }
   ],
   "source": [
    "show_scores(vc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa9db784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted 0 |   Predicted 1 |\n",
      "|---------------+---------------|\n",
      "|         12838 |          1561 |\n",
      "|           334 |           267 |\n",
      "\n",
      "accuracy:              0.8737\n",
      "precision:             0.1461\n",
      "recall:                0.4443\n",
      "f1:                    0.2198\n",
      "roc_auc_discrete:      0.6679\n",
      "roc_auc_continuous:    0.7784\n"
     ]
    }
   ],
   "source": [
    "show_scores(vc, x_eval, y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46a08200",
   "metadata": {},
   "source": [
    "### Prównanie ze zbiorem testowym:\n",
    "\n",
    "accuracy:              0.8722\n",
    "\n",
    "precision:             0.1621\n",
    "\n",
    "recall:                0.4756\n",
    "\n",
    "f1:                    0.2418\n",
    "\n",
    "roc_auc_discrete:      0.6828\n",
    "\n",
    "roc_auc_continuous:    0.7792\n",
    "\n",
    "\n",
    "\n",
    "### Niespotykanie wysoki jak dotąd rezultat f1 oraz całkiem przyzwoite inne metryki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda8e4c",
   "metadata": {},
   "source": [
    "# 8. Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8adead",
   "metadata": {},
   "source": [
    "### Regresja Logistyczna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "165447a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('int_pipe', Pipeline([\n",
    "            ('int', ColumnRemover(0.9998, 1, 0)),\n",
    "            ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int64'))]), make_column_selector(dtype_include=np.int64)),\n",
    "        ('float_pipe', Pipeline([\n",
    "            ('float', ColumnRemover(0.9996, 0.97, 0)),\n",
    "            ('standardization', StandardScaler())]), make_column_selector(dtype_include=np.float64))\n",
    "    ])),\n",
    "    ('selector', SelectKBest(k=33)),\n",
    "    ('model', LogisticRegression(random_state=42, class_weight='balanced'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbc3303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADB_logreg = AdaBoostClassifier(base_estimator=log_reg, n_estimators=5000,\n",
    "    learning_rate=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "976a232e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "NoneType doesn't support sample_weight.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ADB_logreg\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      2\u001b[0m show_scores(ADB_logreg, X_train,y_train)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:142\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    139\u001b[0m sample_weight \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m sample_weight\u001b[39m.\u001b[39msum()\n\u001b[0;32m    141\u001b[0m \u001b[39m# Check parameters\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_estimator()\n\u001b[0;32m    144\u001b[0m \u001b[39m# Clear any previous fit results\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:525\u001b[0m, in \u001b[0;36mAdaBoostClassifier._validate_estimator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    518\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAdaBoostClassifier with algorithm=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m'\u001b[39m\u001b[39m requires \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    519\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthat the weak learner supports the calculation of class \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39malgorithm=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    523\u001b[0m         )\n\u001b[0;32m    524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_fit_parameter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator_, \u001b[39m\"\u001b[39m\u001b[39msample_weight\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 525\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    526\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support sample_weight.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: NoneType doesn't support sample_weight."
     ]
    }
   ],
   "source": [
    "ADB_logreg.fit(X_train, y_train)\n",
    "show_scores(ADB_logreg, X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27e44502",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AdaBoostClassifier' object has no attribute 'n_classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m show_scores(ADB_logreg, x_eval,y_eval)\n",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m, in \u001b[0;36mshow_scores\u001b[1;34m(clf, X, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow_scores\u001b[39m(clf, X, y):\n\u001b[1;32m----> 2\u001b[0m     y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[0;32m      3\u001b[0m     y_pred_prob \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict_proba(X)\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(tabulate(confusion_matrix(y, y_pred), headers\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mPredicted 0\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPredicted 1\u001b[39m\u001b[39m'\u001b[39m], tablefmt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39morgtbl\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:700\u001b[0m, in \u001b[0;36mAdaBoostClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    684\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Predict classes for X.\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \n\u001b[0;32m    686\u001b[0m \u001b[39m    The predicted class of an input sample is computed as the weighted mean\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    699\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 700\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[0;32m    702\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    703\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(pred \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:763\u001b[0m, in \u001b[0;36mAdaBoostClassifier.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    760\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    761\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X(X)\n\u001b[1;32m--> 763\u001b[0m n_classes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_classes_\n\u001b[0;32m    764\u001b[0m classes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[:, np\u001b[39m.\u001b[39mnewaxis]\n\u001b[0;32m    766\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    767\u001b[0m     \u001b[39m# The weights are all 1. for SAMME.R\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AdaBoostClassifier' object has no attribute 'n_classes_'"
     ]
    }
   ],
   "source": [
    "show_scores(ADB_logreg, x_eval,y_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8bcdd6",
   "metadata": {},
   "source": [
    "### Drzewa decyzyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d6b32a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('int_pipe', Pipeline([\n",
    "            ('int', ColumnRemover(0.9998, 0.99, 2)),\n",
    "            ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int64'))]), make_column_selector(dtype_include=np.int64)),\n",
    "        ('float_pipe', Pipeline([\n",
    "            ('float', ColumnRemover(0.9998, 0.96, 15)),\n",
    "        ]), make_column_selector(dtype_include=np.float64))\n",
    "    ])),\n",
    "    ('selector', SelectFromModel(DecisionTreeClassifier(random_state=42))),\n",
    "    ('model', DecisionTreeClassifier(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db032bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADB_dct = AdaBoostClassifier(base_estimator=dct, n_estimators=1000,learning_rate=0.5,\n",
    "                         algorithm='SAMME.R', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "63d19224",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "NoneType doesn't support sample_weight.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ADB_dct\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      2\u001b[0m show_scores(ADB_dct, X_train,y_train)\n\u001b[0;32m      3\u001b[0m show_scores(ADB_dct, x_eval,y_eval)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:142\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    139\u001b[0m sample_weight \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m sample_weight\u001b[39m.\u001b[39msum()\n\u001b[0;32m    141\u001b[0m \u001b[39m# Check parameters\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_estimator()\n\u001b[0;32m    144\u001b[0m \u001b[39m# Clear any previous fit results\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:525\u001b[0m, in \u001b[0;36mAdaBoostClassifier._validate_estimator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    518\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAdaBoostClassifier with algorithm=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m'\u001b[39m\u001b[39m requires \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    519\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthat the weak learner supports the calculation of class \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39malgorithm=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    523\u001b[0m         )\n\u001b[0;32m    524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_fit_parameter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator_, \u001b[39m\"\u001b[39m\u001b[39msample_weight\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 525\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    526\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support sample_weight.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: NoneType doesn't support sample_weight."
     ]
    }
   ],
   "source": [
    "ADB_dct.fit(X_train, y_train)\n",
    "show_scores(ADB_dct, X_train,y_train)\n",
    "show_scores(ADB_dct, x_eval,y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f3241560",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADB_dct = AdaBoostClassifier(base_estimator=dct, n_estimators=2000,learning_rate=0.5,\n",
    "                         algorithm='SAMME.R', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a7b5c9df",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "NoneType doesn't support sample_weight.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ADB_dct\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      2\u001b[0m show_scores(ADB_dct, X_train,y_train)\n\u001b[0;32m      3\u001b[0m show_scores(ADB_dct, x_eval,y_eval)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:142\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    139\u001b[0m sample_weight \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m sample_weight\u001b[39m.\u001b[39msum()\n\u001b[0;32m    141\u001b[0m \u001b[39m# Check parameters\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_estimator()\n\u001b[0;32m    144\u001b[0m \u001b[39m# Clear any previous fit results\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:525\u001b[0m, in \u001b[0;36mAdaBoostClassifier._validate_estimator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    518\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAdaBoostClassifier with algorithm=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m'\u001b[39m\u001b[39m requires \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    519\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthat the weak learner supports the calculation of class \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39malgorithm=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    523\u001b[0m         )\n\u001b[0;32m    524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_fit_parameter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator_, \u001b[39m\"\u001b[39m\u001b[39msample_weight\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 525\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    526\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support sample_weight.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: NoneType doesn't support sample_weight."
     ]
    }
   ],
   "source": [
    "ADB_dct.fit(X_train, y_train)\n",
    "show_scores(ADB_dct, X_train,y_train)\n",
    "show_scores(ADB_dct, x_eval,y_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a371ee7",
   "metadata": {},
   "source": [
    "### Kolejny error: tym razem AdaBoost\n",
    "\n",
    "Po wielu godzinach ponownego i intensywnego researchu w celu rozwiązania problemu nie udało się rozwiązać kwestii tego erroru. Kod w repozytorium zaespołu budowy na githubie jest wykonany i ma outputy. \n",
    "Natomiast w celu weryfikacji wyników notebooka budowy i sprawdzenia czy oryginał zadziała na zbiorze treningowym i testowym postanowiliśmy wykonać go raz jeszcze.\n",
    "Po odpaleniu oryginalnego notebooka również pojawia się ten sam błąd.\n",
    "\n",
    "### Wniosek:\n",
    "### Kod grupy budowy nie wykonuje się poprawnie."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2599883",
   "metadata": {},
   "source": [
    "# Próba rozwiązania"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccde8bd9",
   "metadata": {},
   "source": [
    "### Spróbowaliśmy rozwiązać kwestię pojawienia się komunikatu - ValueError: NoneType doesn't support sample_weight.\n",
    "Dodaliśmy sample_weight=None.\n",
    "Kod nie działa zarówno w wersji zespołu budowy z repozytorium na danych treningowych i testowych jak i na danych treningowych i walidacyjnych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b23213cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "NoneType doesn't support sample_weight.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ADB_logreg\u001b[39m.\u001b[39;49mfit(X_train, y_train, sample_weight\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m      2\u001b[0m show_scores(ADB_logreg, X_train,y_train)\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:142\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    139\u001b[0m sample_weight \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m sample_weight\u001b[39m.\u001b[39msum()\n\u001b[0;32m    141\u001b[0m \u001b[39m# Check parameters\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_estimator()\n\u001b[0;32m    144\u001b[0m \u001b[39m# Clear any previous fit results\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32md:\\Anaconda2\\envs\\valid\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:525\u001b[0m, in \u001b[0;36mAdaBoostClassifier._validate_estimator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    518\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAdaBoostClassifier with algorithm=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m'\u001b[39m\u001b[39m requires \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    519\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthat the weak learner supports the calculation of class \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39malgorithm=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    523\u001b[0m         )\n\u001b[0;32m    524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_fit_parameter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator_, \u001b[39m\"\u001b[39m\u001b[39msample_weight\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 525\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    526\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support sample_weight.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: NoneType doesn't support sample_weight."
     ]
    }
   ],
   "source": [
    "ADB_logreg.fit(X_train, y_train, sample_weight=None)\n",
    "show_scores(ADB_logreg, X_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7035f614",
   "metadata": {},
   "source": [
    "### Próby rozwiązania do niczego nie doprowadziły"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af2e881e",
   "metadata": {},
   "source": [
    "# Przejdźmy do podsumowania"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fc8772e",
   "metadata": {},
   "source": [
    "### Wyniki roc_auc na danych testowych\n",
    "\n",
    "Regresja logistyczna bez param.: 0.781 |\n",
    "Regresja logistyczna z param.: 0.782\n",
    "| Ilości zmiennych przy niepogorszonych wynikach\n",
    "w regresji logistycznej:\n",
    "|-K_best: 33\n",
    "|-SFM: 114\n",
    "|-SFS: 40\n",
    "|-RFE: 72\n",
    "|-PCA: 3 |\n",
    "\n",
    "Drzewo decyzyjne bez param.: 0.554 |\n",
    "Drzewo decyzyjne z param.: 0.588 \n",
    "| Ilości zmiennych przy niepogorszonych wynikach\n",
    "w drzewie decyzyjnym:\n",
    "|-K_best: 106\n",
    "|-SFM: 22\n",
    "|-SFS: 70\n",
    "|-RFE: 26\n",
    "|-PCA: 14 |\n",
    "\n",
    "|Model   |No_hyper   |with_hyper   |\n",
    "|---|---|---|\n",
    "|SVC   |0.670   |0.768   |\n",
    "|KNN   |0.542 |0.570   |\n",
    "|rand_forest   |0.794   | 0.821   |\n",
    "|AdaBoost logreg  |0.774   |0.799   |\n",
    "|AdaBoost dct  |0.676   |0.684   |\n",
    "|Voting   | ***  | 0.779  | "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baf6b978",
   "metadata": {},
   "source": [
    "# Walidacja - dane walidacyjne\n",
    " ? - brak możliwości weryfikacji wyniku |\n",
    " @ - brak implementacji w ostatecznym projekcie\n",
    "### Wyniki roc_auc na danych walidacyjnych\n",
    "\n",
    "Regresja logistyczna bez param.: 0.786 |\n",
    "Regresja logistyczna z param.: 0.789\n",
    "| Ilości zmiennych przy niepogorszonych wynikach\n",
    "w regresji logistycznej:\n",
    "|-K_best: 33\n",
    "|-SFM: 114\n",
    "|-SFS: ?\n",
    "|-RFE: ?\n",
    "|-PCA: ? |\n",
    "\n",
    "Drzewo decyzyjne bez param.: 0.561 |\n",
    "Drzewo decyzyjne z param.: 0.604 \n",
    "| Ilości zmiennych przy niepogorszonych wynikach\n",
    "w drzewie decyzyjnym:\n",
    "|-K_best: 33\n",
    "|-SFM: 114\n",
    "|-SFS: ?\n",
    "|-RFE: ?\n",
    "|-PCA: ? | \n",
    "\n",
    "\n",
    "|Model   |No_hyper   |with_hyper   |\n",
    "|---|---|---|\n",
    "|SVC   |0.642  |  ?     |\n",
    "|KNN   |  @   |  @     |\n",
    "|rand_forest   |0.806   | 0.824   |\n",
    "|AdaBoost logreg  |  ?     |    ?   |\n",
    "|AdaBoost dct  |  ?     |  ?     |\n",
    "|Voting   | ***  | 0.778  | \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "866f8c67",
   "metadata": {},
   "source": [
    "# Podsumowanie całej walidacji \n",
    "Zespół budowy nie miał łatwego zadania. Ich dataset jest nieprzyjazny, a potęguje to fakt syntetyczności danych nie reprezentujących dosłownie niczego. \n",
    "\n",
    "\n",
    "### Pozytywy:\n",
    "Zespół budowy wykazał się pomysłowością i kreatywnością. Zrobił wyczerującą i obszerną analizę eksploracyjną. Stworzył również do tego własne autorskie narzędzia. \n",
    "\n",
    "Zespół wykazał się doborem  modeli, stosowaniem rozmaitych technik inżynierii cech wraz z parametrami oraz selekcji hiperparametrów dla modeli. Przeszukał ogromne przestrzenie parametrów w celu otrzymania jak najlepszego wyniku w zależności od modelu. Powyższe kosztowało ich dużo cierpliwości i zużytego prądu.\n",
    "\n",
    "Poprawnie interpretował metryki oraz wnioskował na ich podstawie w celu poprawienia wyników modeli.\n",
    "\n",
    "\n",
    "### Negatywy:\n",
    "Tak jak zauważamy na samym początku walidacji brak pliku z wersjami paczek - requirements. Bez podania wersji i cech środowiska programistycznego nie można odtworzyć wyników badania. Sprawia to, że w świecie naukowym czy w pewnych przypadkach komercyjnych projekt jest zwyczajnie do kosza.\n",
    "\n",
    "Cały projekt jest w 1 notebooku. Dobrą praktyką jest rozdzielenie projektu na różne pliki w tym na oddzielne skrypty, której mają za zadanie przechowywać narzędzia wywoływane w projekcie. Ma to oszczędzić miejsce i sprawia, że projekt jest czytelniejszy.\n",
    "\n",
    "Stosowanie stworzonych w całości przez autorów narzędzi (w tym przypadku ColumnRemovera) i niepoinformowanie czy brak budowy działającej funkcji spowodował niemożność wykonania operacji votingu. Zespół walidacji niepotrzebnie stracił wiele godzin na próbę rozwiązania problemu. Proponujemy stosowanie gotowych rozwiązań z istniejących bibliotek.\n",
    "\n",
    "Stosowanie PCA przez autorów do drastycznej redukcji wymiarowości zmiennych. Nie zawsze chcemy dokonywać przkształceń liniowych, które mogą zaburzyć nam predykcyjność/poprawę predykcyjności modelu. Tzn. redukcja ilości zmiennych do zmiennych nieskorelowanych może mieć zły wpływ na działanie modelu. Również zaburza ważość cech co negatywnie wpływa na wyjaśnialność modelu. Wyjaśnialność modelu jest kluczowa w zadaniach takich jak klasyfikacja.  Bibliografia (https://www.yourdatateacher.com/2022/07/11/why-you-shouldnt-use-pca-in-a-supervised-machine-learning-project/), (https://blog.kxy.ai/5-reasons-you-should-never-use-pca-for-feature-selection/), (https://www.kaggle.com/general/215905),\n",
    "\n",
    "Wyniki modeli: Zespół budowy w powyższej tabli z podsumowaniem metryki roc_auc i ilości cech, zawierającej wyniki budowy (z danych treningowych i testowych ) podaje wyniki z niewiadomo skąd, w głównym notebooku brak outputu o ilości cech PCA i RFE oraz metrykach support vector machine z dobranymi parametrami. Domyślamy się iż jest to spowodowane długim czasem oczekiwania i dużą złożonością obliczeniową (nam też nie chciało się obliczyć). Jednakże w takim przypadku należałoby nie umieszczać wyników, których nie możemy odtworzyć i zobaczyć, nie wierzyć na słowo autorom.\n",
    "\n",
    "Powyższa uwaga tyczy się umieszczenia modelu K-nearest neighbouhrs, tego modelu zwyczajnie nie ma w finalnym pliku.\n",
    "\n",
    "Ostatnią uwagą jest brak wyboru modelu wdrożeniowego. Mimo kompletnego braku kontekstu danych i ich bezsensowności zwasze należy wybrać model, ponieważ to jest sedno projektu. Tabelka z wynikami metryk modeli nic nie mówi. Projekt zwyczajnie nie jest skończony. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
